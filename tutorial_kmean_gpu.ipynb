{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import kmeans__gpu_v1\n",
    "a , b = 1000, 1000\n",
    "numpy_arr =np.random.normal(127,127,size=(a,b,3)).astype(int)\n",
    "\n",
    "# Can try with real image:\n",
    "# from PIL import Image # pip instal PIL\n",
    "# img = Image.open(\"p1.jpg\").convert('RGB')\n",
    "# numpy_arr = np.array(img.resize(size=(a,b)))\n",
    "# img = Image.fromarray(numpy_arr, 'RGB')\n",
    "# img.show()\n",
    "model = k_means_gpu.k_means_gpu(k=70, convergence=-0.001, num_iteration = 1, compute_device = \"default\", vram = \"2.5GB\")\n",
    "model.fit(numpy_arr, retrain = False, verbose = True)\n",
    "data = model.compress_input(numpy_arr, compute_device = \"default\",save_array = False, data_path = \"compress_array\")\n",
    "\n",
    "#unquote to show real image\n",
    "# img = Image.fromarray(data, 'RGB')\n",
    "# img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute centroid EXAMPLE LOOP OVER DATASET ( simulate image)\n",
    "%%time\n",
    "from PIL import Image\n",
    "\n",
    "a , b = 1000, 1000\n",
    "number_of_simulated_image = 10\n",
    "k_number_of_cluster = 70\n",
    "dataset = np.array([np.random.normal(127,127,size=(a,b,3)).astype(int) for i in range (number_of_simulated_image)])\n",
    "\n",
    "model = k_means_gpu(k=k_number_of_cluster, convergence=-0.001, num_iteration = 1, compute_device = \"default\", vram = \"2.5GB\")\n",
    "\n",
    "while not model.convergence_eval():\n",
    "    for i in range(len(numpy_arr)):\n",
    "        \n",
    "        random_number = torch.randint(0, len(numpy_arr), (1,))\n",
    "        random_sample = dataset[random_sample]\n",
    "        \n",
    "        if i == 0:\n",
    "            model.fit(random_sample,retrain = False, verbose = True)\n",
    "        model.fit(random_sample, retrain = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "# Import py containing kmean\n",
    "import kmeans__gpu_v1\n",
    "\n",
    "\n",
    "# test data choice between image or random numpy array\n",
    "# the data can be of any size or shape but need to be a pytorch_tensor or numpy_array\n",
    "# the data size limite is set by your RAM memory. You will need to split the data if higher than it (look for last example)\n",
    "img = PIL.Image.open(\"p1.jpg\").convert('RGB')\n",
    "numpy_arr = np.array(img.resize(size=(708,708)))\n",
    "numpy_arr =np.random.normal(127,127,size=(32,32,3)).astype(int) #simulate image with random point of {size=} as a shape \n",
    "\n",
    "# You can choice the number for k-fold {k=}, the thresold with {convergence=}, the max number of iteration with{num_iteration=}\n",
    "# You can also set the maximum amount of VRAM you which to use during the computation of the centroid with {vram=}\n",
    "# Compute will auto scale with the amount of vram and not bridge this limi\n",
    "# can choice where to compute with computer_device::option: \"cuda:0\" or \"cuda:1\", etc.. and , \"cpu\", default will choice gpu if available\n",
    "model_km = k_means_gpu(k=2, convergence = 0.001, num_iteration = 300, compute_device = \"default\", vram = \"2.5GB\")\n",
    "# or just:  to setup the model\n",
    "model_km = k_means_gpu(k=30)\n",
    "# fit model\n",
    "model_km.fit(numpy_arr, retrain = False, verbose = True)\n",
    "\n",
    "\n",
    "# can save centroids after compute, will save a {self,model_path}{model_name}.pt file\n",
    "model_km.save_centroid(self,model_path = \"\",model_name = \"centroids\")\n",
    "# can load other saved centroid\n",
    "model_km.load_centroid(self,path_to_model_to_load=\"centroids.pt\")\n",
    "\n",
    "# $WARNING$: no VRAM management yet developed, i would recommend compute_device = \"cpu\" or to upload a matrix smaller than your VRAM Memory size\n",
    "# encode data with centroid class : int going from 1,2,..... the amount set during compute {k=}:\n",
    "# can choice where to compute with computer_device::option: \"cuda:0\" or \"cuda:1\", etc.. and , \"cpu\", default will choice gpu if available\n",
    "encode = model_km.encode(numpy_arr, compute_device = \"default\",save_array = False, data_path = \"encoded_array\")\n",
    "print(encode)\n",
    "# decode the encoded output to the closest value:\n",
    "# can choice where to compute with computer_device::option: \"cuda:0\" or \"cuda:1\", etc.. and , \"cpu\", default will choice gpu if available\n",
    "decode = model_km.decode(encode, compute_device = \"default\",save_array = False, data_path = \"decoded_array\") #need to set the correct dtype like int if you are doing image at the end\n",
    "img = Image.fromarray(data, 'RGB')\n",
    "img\n",
    "\n",
    "# encode-decode in one go -> return numpy array | \n",
    "# can choice where to compute with computer_device::option: \"cuda:0\" or \"cuda:1\", etc.. and , \"cpu\", default will choice gpu if available\n",
    "compressed = model_km.model.compress_input(numpy_arr, compute_device = \"default\",save_array = False, data_path = \"compress_array\")\n",
    "\n",
    "img = Image.fromarray(data, 'RGB')\n",
    "img\n",
    "\n",
    "# you save the compute output instead of storing it -> save {data_path}.npy\n",
    "encode = model_km.encode(numpy_arr, compute_device = \"default\",save_array = False, data_path = \"encoded_array\")\n",
    "model_km.decode(encode, compute_device = \"default\",save_array = False, data_path = \"decoded_array\")\n",
    "model_km.compress_input(numpy_arr, compute_device = \"default\",save_array = False, data_path = \"compress_array\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPEEDTEST:\n",
    "%%time\n",
    "numpy_arr=np.random.normal(127,127,size=(1000,1000,3)).astype(int)\n",
    "model = k_means_gpu(k=30, convergence=0.01)\n",
    "model.fit(numpy_arr, retrain = False, verbose = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('tradd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9576c99980f95e051990d4e759e2b8bed23c4dbd32ead604c26a9cabcb988379"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
