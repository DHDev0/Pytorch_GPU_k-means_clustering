{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "import kmeans__gpu_v0\n",
    "\n",
    "\n",
    "#test data choice between image or random numpy array\n",
    "#the data can be of any size or shape but need to be a pytorch_tensor or numpy_array\n",
    "#the data size limit is set by your RAM memory. You will need to split the data if higher than your RAM memory (look for last example)\n",
    "img = PIL.Image.open(\"p1.jpg\").convert('RGB')\n",
    "numpy_arr = np.array(img.resize(size=(708,708)))\n",
    "\n",
    "numpy_arr =np.random.normal(127,127,size=(32,32,3)).astype(int) #simulate image with random point of {size=} as a shape \n",
    "\n",
    "# You can choice the number for k-fold {k=}, the thresold with {convergence=}, the max number of iteration with{num_iteration=}\n",
    "# You can also set the maximum amount of VRAM you which to use during the computation of the centroid with {vram=}\n",
    "# Compute will auto scale with the amount of vram and not bridge this limi\n",
    "# can choice where to compute with computer_device::option: \"cuda:0\" or \"cuda:1\", etc.. and , \"cpu\", default will choice gpu if available\n",
    "model_km = k_means_gpu(k=2, convergence = 0.001, num_iteration = 300, compute_device = \"default\", vram = \"2.5GB\")\n",
    "#or just:  to setup the model\n",
    "model_km = k_means_gpu(k=30)\n",
    "#fit model\n",
    "model_km.fit(numpy_arr, retrain = False, verbose = True)\n",
    "\n",
    "\n",
    "#can save centroids after compute, will save a {self,model_path}{model_name}.pt file\n",
    "model_km.save_centroid(self,model_path = \"\",model_name = \"centroids\")\n",
    "#can load other saved centroid\n",
    "model_km.load_centroid(self,path_to_model_to_load=\"centroids.pt\")\n",
    "\n",
    "# $WARNING$: no VRAM management yet developed, i would recommend compute_device = \"cpu\" or to upload a matrix smaller than your VRAM Memory size\n",
    "# encode data with centroid class : int going from 1,2,..... the amount set during compute {k=}:\n",
    "# can choice where to compute with computer_device::option: \"cuda:0\" or \"cuda:1\", etc.. and , \"cpu\", default will choice gpu if available\n",
    "model_km.encode(self,pointer_to_encode, compute_device = \"default\",save_array = False, data_path = \"encoded_array\")\n",
    "# decode the encoded output to the closest value:\n",
    "# can choice where to compute with computer_device::option: \"cuda:0\" or \"cuda:1\", etc.. and , \"cpu\", default will choice gpu if available\n",
    "model_km.decode(numpy_arr, compute_device = \"default\",save_array = False, data_path = \"decoded_array\") #need to set the correct dtype like int if you are doing image at the end\n",
    "# encode-decode in one go -> return numpy array | \n",
    "# can choice where to compute with computer_device::option: \"cuda:0\" or \"cuda:1\", etc.. and , \"cpu\", default will choice gpu if available\n",
    "model_km.model.compress_input(numpy_arr, compute_device = \"default\",save_array = False, data_path = \"compress_array\")\n",
    "\n",
    "\n",
    "#you save the compute output instead thant storing it -> save {data_path}.npy\n",
    "encode(self,pointer_to_encode, compute_device = \"default\",save_array = False, data_path = \"encoded_array\")\n",
    "decode(numpy_arr, compute_device = \"default\",save_array = False, data_path = \"decoded_array\")\n",
    "model.compress_input(numpy_arr, compute_device = \"default\",save_array = False, data_path = \"compress_array\")\n",
    "\n",
    "#not optimize yet but, if your dataset contain multiple image. you can loop over all of them. such as:\n",
    "numpy_arr_dataset = [ np.random.normal(127,127,size=(32,32,3)).astype(int) for image in range(10) ] #simulate a dataset of \n",
    "model_km = k_means_gpu(k=2, convergence = 0.001, num_iteration = 1, compute_device = \"default\", vram = \"2.5GB\")\n",
    "\n",
    "while not k_means_gpu.convergence():\n",
    "    for i in range(len(numpy_arr_dataset))\n",
    "        if i == 0:\n",
    "            model_km.fit(numpy_arr_dataset[i], data, retrain = False, verbose = True):\n",
    "        model_km.fit(numpy_arr_dataset[i], data, retrain = True, verbose = True)\n",
    "        \n",
    "# SPEEDTEST:\n",
    "# %%time\n",
    "# numpy_arr=np.random.normal(127,127,size=(1000,1000,3)).astype(int)\n",
    "# model = k_means_gpu(k=30, convergence=0.01)\n",
    "# model.fit(numpy_arr, retrain = False, verbose = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('tradd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9576c99980f95e051990d4e759e2b8bed23c4dbd32ead604c26a9cabcb988379"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
